using julia to do some sci-ml or other things
# ğŸŒ¡ï¸ One-Line Temperature Forecasting with Julia  
# ğŸŒ¡ï¸ Juliaã§ã®ãƒ¯ãƒ³ãƒ©ã‚¤ãƒ³æ°—æ¸©äºˆæ¸¬

> A comparative modeling project using Julia to predict tomorrow's temperature using only one day's data. This study evaluates and contrasts differential equations, deep learning, and probabilistic methods within a unified experimental design.  
> æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€**1æ—¥ã®æ°—æ¸©ãƒ‡ãƒ¼ã‚¿**ã®ã¿ã‚’ä½¿ã£ã¦ç¿Œæ—¥ã®æ°—æ¸©ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã«ã€Juliaã‚’ç”¨ã„ã¦ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆå¾®åˆ†æ–¹ç¨‹å¼ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã€ãƒ™ã‚¤ã‚ºæ¨è«–ï¼‰ã‚’æ¯”è¼ƒæ¤œè¨¼ã—ãŸå®Ÿé¨“çš„ãªå–ã‚Šçµ„ã¿ã§ã™ã€‚

---

## ğŸ§  Project Background & Motivation  
## ğŸ§  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®èƒŒæ™¯ã¨å‹•æ©Ÿ

This project challenges conventional time-series forecasting approaches by minimizing the input: **Can we predict tomorrowâ€™s temperature using only one line of daily data?**

Instead of relying on long sequences of past data, I investigate how different modeling paradigms handle minimal, high-noise, nonlinear input. Itâ€™s both a practical and philosophical inquiry into model expressiveness, generalization, and design across scientific and machine learning domains.

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ä¸€èˆ¬çš„ãªæ™‚ç³»åˆ—äºˆæ¸¬æ‰‹æ³•ã¨ã¯ç•°ãªã‚Šã€å…¥åŠ›ã‚’æ¥µé™ã¾ã§åˆ¶é™ã—ã€**ã€ŒãŸã£ãŸ1è¡Œã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã§ãã‚‹ã®ã‹ï¼Ÿã€**ã¨ã„ã†æŒ‘æˆ¦çš„ãªãƒ†ãƒ¼ãƒã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚

é•·æœŸé–“ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã«é ¼ã‚‹ã®ã§ã¯ãªãã€æœ€å°é™ã§ãƒã‚¤ã‚ºã®å¤šã„éç·šå½¢ãªå…¥åŠ›ã«å¯¾ã—ã¦ã€ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã©ã®ã‚ˆã†ã«å¯¾å¿œã§ãã‚‹ã‹ã‚’æ¯”è¼ƒã—ã¾ã—ãŸã€‚ã“ã‚Œã¯å®Ÿè·µçš„ã‹ã¤ãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ€æƒ³çš„ãªæ¢æ±‚ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚

---

## ğŸ“Š Dataset  
## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦

- **Source**: Daily temperature data from the Japan Meteorological Agency  
- **Years**: 2020, 2021, 2022  
- **Target**: Max daily temperature  
- **Format**: CSV, 365 entries/year  
- **Preprocessing**: Transformed into `Float32` matrices using `CSV.jl` & `DataFrames.jl`

- **å‡ºå…¸**: æ—¥æœ¬æ°—è±¡åºã®æ°—æ¸©è¦³æ¸¬ãƒ‡ãƒ¼ã‚¿  
- **å¯¾è±¡å¹´**: 2020å¹´ã€œ2022å¹´  
- **ä½¿ç”¨é …ç›®**: æ—¥æœ€é«˜æ°—æ¸©  
- **å½¢å¼**: CSVï¼ˆ365è¡Œï¼‰  
- **å‰å‡¦ç†**: `CSV.jl`, `DataFrames.jl` ã§èª­ã¿è¾¼ã¿ã€Float32è¡Œåˆ—ã«å¤‰æ›

---

## ğŸ§® Method 1: Differential Equations  
## ğŸ§® æ–¹æ³•â‘ ï¼šå¾®åˆ†æ–¹ç¨‹å¼ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°

### ğŸ“Œ Principle  
Based on heat transfer and energy conservation:

\[
\frac{dT}{dt} = f(T, t)
\]

### ğŸ“¦ Tools
- `DifferentialEquations.jl`
- `DiffEqFlux.jl`

### ğŸ§ª Techniques Tried
- Manually derived ODEs
- Neural ODEs
- Nonlinear input transformations (e.g., \(x^4\))
- Second-order ODEs
- GRU/LSTM hybrids

### âŒ Limitations
- Requires physics knowledge
- Slow and unstable
- Inaccurate in noisy real-world data

### ğŸ“Œ åŸç†  
ç†±ã‚¨ãƒãƒ«ã‚®ãƒ¼ä¿å­˜ãƒ»æ”¾å°„å‰‡ï¼ˆã‚¹ãƒ†ãƒ•ã‚¡ãƒ³ï¼ãƒœãƒ«ãƒ„ãƒãƒ³ã®æ³•å‰‡ï¼‰ã«åŸºã¥ãï¼š

\[
\frac{dT}{dt} = f(T, t)
\]

### ğŸ“¦ ä½¿ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- `DifferentialEquations.jl`
- `DiffEqFlux.jl`

### ğŸ§ª è©¦ã—ãŸæ‰‹æ³•
- æ‰‹ä½œæ¥­ã«ã‚ˆã‚‹ç‰©ç†å¾®åˆ†æ–¹ç¨‹å¼
- Neural ODE
- éç·šå½¢å…¥åŠ›ï¼ˆä¾‹ï¼š\(x^4\)ï¼‰
- 2éšå¾®åˆ†æ–¹ç¨‹å¼
- GRUãƒ»LSTM ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹é€ 

### âŒ èª²é¡Œ
- ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ãŒé›£è§£
- æ•°å€¤ä¸å®‰å®šãƒ»é…ã„
- ç¾å®Ÿä¸–ç•Œã®ãƒã‚¤ã‚ºã«å¼±ã„

---

## ğŸ¤– Method 2: Machine Learning with Flux.jl  
## ğŸ¤– æ–¹æ³•â‘¡ï¼šFluxã«ã‚ˆã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯

### ğŸ“Œ Principle  
Supervised learning approximation:  
\[
T_{\text{today}} \rightarrow T_{\text{tomorrow}}
\]

### ğŸ“¦ Tools
- `Flux.jl`

### ğŸ§ª Models
- MLP
- LSTM
- GRU
- Transformer

### âœ… Strengths
- High accuracy
- Stable training
- GRU and Transformer were top performers

### ğŸ“Œ åŸç†  
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ä»¥ä¸‹ã®å†™åƒã‚’è¿‘ä¼¼ï¼š

\[
T_{\text{today}} \rightarrow T_{\text{tomorrow}}
\]

### ğŸ“¦ ä½¿ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- `Flux.jl`

### ğŸ§ª ãƒ¢ãƒ‡ãƒ«
- MLP
- LSTM
- GRUï¼ˆæœ€ã‚‚ç²¾åº¦è‰¯å¥½ï¼‰
- Transformerï¼ˆæœ€é«˜ã®è¿‘ä¼¼æ€§èƒ½ï¼‰

### âœ… å¼·ã¿
- äºˆæ¸¬ç²¾åº¦ãŒé«˜ã„
- å®‰å®šã—ãŸå­¦ç¿’ãŒå¯èƒ½

---

## ğŸ“ˆ Method 3: Probabilistic Modeling  
## ğŸ“ˆ æ–¹æ³•â‘¢ï¼šç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬ï¼ˆãƒ™ã‚¤ã‚ºæ¨è«–ï¼‰

### ğŸ“Œ Principle  
Modeling uncertainty via posterior:

\[
P(\theta | \text{Data}) = \frac{P(\text{Data}|\theta)P(\theta)}{P(\text{Data})}
\]

### ğŸ“¦ Tools
- `Turing.jl`
- `AbstractGPs.jl`

### ğŸ§ª Models
- Bayesian Neural Network (BNN)
- Gaussian Process (GP)
- Deep Kernel Learning (DKL)

### âŒ Limitations
- Very slow
- Complex and fragile
- Accuracy lower than deep learning

### ğŸ“Œ åŸç†  
ä¸ç¢ºå®Ÿæ€§ã‚’ç¢ºç‡åˆ†å¸ƒã§è¡¨ç¾ï¼š

\[
P(\theta | \text{Data}) = \frac{P(\text{Data}|\theta)P(\theta)}{P(\text{Data})}
\]

### ğŸ“¦ ä½¿ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- `Turing.jl`
- `AbstractGPs.jl`

### ğŸ§ª ãƒ¢ãƒ‡ãƒ«
- ãƒ™ã‚¤ã‚ºãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆBNNï¼‰
- ã‚¬ã‚¦ã‚¹éç¨‹ï¼ˆGPï¼‰
- æ·±å±¤ã‚«ãƒ¼ãƒãƒ«å­¦ç¿’ï¼ˆDKLï¼‰

### âŒ èª²é¡Œ
- éå¸¸ã«è¨ˆç®—ãŒé‡ã„
- è¤‡é›‘ã§ä¸å®‰å®š
- ç²¾åº¦ã¯NNã‚ˆã‚Šä½ã„

---

## ğŸ§¾ Comparative Summary  
## ğŸ§¾ æ‰‹æ³•æ¯”è¼ƒã¾ã¨ã‚

| Method         | Performance | Pros                  | Cons                   |
|----------------|-------------|------------------------|------------------------|
| Differential Eq| âŒ Poor      | Physically grounded    | Complex, inaccurate    |
| MLP            | âšª Average   | Easy to implement      | Limited capacity       |
| LSTM           | âœ… Good      | Captures sequences     | Slower training        |
| GRU            | ğŸŒŸ Best      | Accurate + fast        | Needs tuning           |
| Transformer    | ğŸ”¥ Excellent | Powerful approximation | Heavy and complex      |
| Bayesian Models| âŒ Poor      | Uncertainty modeling   | Slow, unstable         |

---

## ğŸ§ª My Original Contributions  
## ğŸ§ª ç§ã®ç‹¬è‡ªã®å–ã‚Šçµ„ã¿ãƒ»å·¥å¤«

This project stands out because of its **cross-paradigm comparative design**. Instead of sticking to one method, I explored how **physics, deep learning, and probability theory** approach the same minimalist task.

- Tested multiple **modeling philosophies** on the same problem
- Developed **hybrid systems** (Neural ODE + GRU)
- Built a **Transformer** from scratch using Flux
- Implemented **Deep Kernel Learning** using Juliaâ€™s advanced libraries
- Documented **failures and insights**, not just successes
- Compared methods not only on accuracy, but also on **theoretical assumptions and computational cost**

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æœ€ã‚‚ç‰¹å¾´çš„ãªç‚¹ã¯ã€**å…¨ãç•°ãªã‚‹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°åˆ†é‡ã‚’æ¨ªæ–­çš„ã«æ¯”è¼ƒ**ã—ãŸã¨ã“ã‚ã«ã‚ã‚Šã¾ã™ã€‚

- 1è¡Œã®æ°—æ¸©ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã™ã‚‹ã¨ã„ã†åŒä¸€å•é¡Œã«ã€ç‰©ç†ãƒ¢ãƒ‡ãƒ«ãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ»ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã‚’é©ç”¨
- Neural ODEã¨GRUã‚’çµ„ã¿åˆã‚ã›ãŸ**ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ§‹é€ **ã‚’é–‹ç™º
- Fluxã§**Transformerã‚’è‡ªä½œ**
- Juliaã®é«˜åº¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§**Deep Kernel Learning**ã‚’è©¦è¡Œ
- æˆåŠŸä¾‹ã ã‘ã§ãªã**å¤±æ•—ã¨è€ƒå¯Ÿã‚‚è©³ç´°ã«è¨˜éŒ²**
- ç²¾åº¦ã ã‘ã§ãªãã€**ç†è«–çš„èƒŒæ™¯ã¨è¨ˆç®—ã‚³ã‚¹ãƒˆ**ã‚‚è©•ä¾¡å¯¾è±¡ã«å«ã‚ãŸ

---

## ğŸ“š References  
## ğŸ“š å‚è€ƒæ–‡çŒ®

- Flux.jl  
- Turing.jl  
- DiffEqFlux.jl  
- AbstractGPs.jl  
- Japan Meteorological Agency / æ—¥æœ¬æ°—è±¡åº

---




